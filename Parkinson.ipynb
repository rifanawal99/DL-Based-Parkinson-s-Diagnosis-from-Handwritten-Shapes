{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLM4mhQjNoHB"
      },
      "outputs": [],
      "source": [
        "# Function to filter out corrupted images\n",
        "def filter_corrupted_images(folder_path):\n",
        "    num_skipped = 0\n",
        "    for fname in os.listdir(folder_path):\n",
        "        fpath = os.path.join(folder_path, fname)\n",
        "        try:\n",
        "            fobj = open(fpath, \"rb\")\n",
        "            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
        "        finally:\n",
        "            fobj.close()\n",
        "\n",
        "        if not is_jfif:\n",
        "            num_skipped += 1\n",
        "            # Delete corrupted image\n",
        "            os.remove(fpath)\n",
        "    print(f\"Deleted {num_skipped} images in {folder_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace these with your actual class names\n",
        "class_names = [\"Parkinson\", \"Healthy\"]"
      ],
      "metadata": {
        "id": "MWCUPuWtN1Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify image size and batch size\n",
        "image_size = (64, 64)  # Resized image size\n",
        "batch_size = 128"
      ],
      "metadata": {
        "id": "2IDihAD_N8mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main folder path\n",
        "main_folder_path = \"G:\\\\Rifa\\\\Parkinson\\\\Created\\\\Spiral\"\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.feature import hog\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.layers import SeparableConv2D, MaxPooling2D,\n",
        "Flatten, Dense, Input, Attention, concatenate\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "rIdaXTXhOAbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract HOG features from an image\n",
        "def extract_hog_features(image):\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    fd, _ = hog(gray_image, orientations=8, pixels_per_cell=(8, 8),\n",
        "cells_per_block=(1, 1), visualize=True)\n",
        "    return fd.flatten()"
      ],
      "metadata": {
        "id": "MdrOcwT_OEpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main folder path\n",
        "main_folder_path = \"G:\\\\Rifa\\\\Parkinson\\\\Created\\\\Spiral\""
      ],
      "metadata": {
        "id": "hDuNJrSGOI5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the dataset\n",
        "images = []\n",
        "labels = []\n",
        "class_names = ['Healthy', 'Parkinson']\n",
        "image_size = (64, 64)\n",
        "\n",
        "def filter_corrupted_images(folder_path):\n",
        "    pass  # Add your implementation to filter corrupted images if\n",
        "needed\n",
        "\n",
        "for class_name in class_names:\n",
        "    folder_path = os.path.join(main_folder_path, class_name)\n",
        "    filter_corrupted_images(folder_path)\n",
        "    for fname in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, fname)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, image_size)\n",
        "        images.append(img)\n",
        "        labels.append(class_name)"
      ],
      "metadata": {
        "id": "C7UzQWn1ONw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)"
      ],
      "metadata": {
        "id": "c8PS2YTaOS0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training (70%), validation (15%), and test\n",
        "(15%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(images, labels,\n",
        "test_size=0.3, random_state=1337)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp,\n",
        "test_size=0.5, random_state=1337)"
      ],
      "metadata": {
        "id": "CYo8nH-fOXA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract HOG features\n",
        "X_train_hog = np.array([extract_hog_features(img) for img in\n",
        "X_train])\n",
        "X_val_hog = np.array([extract_hog_features(img) for img in X_val])\n",
        "X_test_hog = np.array([extract_hog_features(img) for img in\n",
        "X_test])"
      ],
      "metadata": {
        "id": "u96VyMsYOaay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input shape for the CNN\n",
        "image_size = (64, 64)"
      ],
      "metadata": {
        "id": "b1lJ2oCpOgJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input layer for the CNN\n",
        "cnn_input = Input(shape=(image_size[0], image_size[1], 3))"
      ],
      "metadata": {
        "id": "2iLQZtk4OgTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define CNN layers\n",
        "conv1 = SeparableConv2D(32, (3, 3), activation='gelu')(cnn_input)\n",
        "max_pool1 = MaxPooling2D((2, 2))(conv1)"
      ],
      "metadata": {
        "id": "g1WhjlTEOlCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add Attention layer\n",
        "attention1 = Attention()([max_pool1, max_pool1])"
      ],
      "metadata": {
        "id": "NdDQwBubOlFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the rest of the CNN layers\n",
        "conv2 = SeparableConv2D(64, (3, 3), activation='gelu')(attention1)\n",
        "max_pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "flatten = Flatten()(max_pool2)\n",
        "dense = Dense(64, activation='gelu')(flatten)"
      ],
      "metadata": {
        "id": "zJkhilO6Ozjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the CNN model\n",
        "cnn_model = Model(inputs=cnn_input, outputs=dense)"
      ],
      "metadata": {
        "id": "DYemgVDOOzwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a fully connected model for HOG features\n",
        "hog_input = Input(shape=(X_train_hog.shape[1],))\n",
        "hog_model = Dense(64, activation='gelu')(hog_input)"
      ],
      "metadata": {
        "id": "hr82fsxVOz_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate the CNN and HOG models\n",
        "concatenated = concatenate([cnn_model.output, hog_model])"
      ],
      "metadata": {
        "id": "eBsEmPQ-O7ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add more layers as needed\n",
        "merged_model = Dense(64, activation='gelu')(concatenated)\n",
        "output = Dense(len(class_names),\n",
        "activation='sigmoid')(merged_model)"
      ],
      "metadata": {
        "id": "hrdqrgVcO9xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the final model\n",
        "final_model = Model(inputs=[cnn_model.input, hog_input],\n",
        "outputs=output)"
      ],
      "metadata": {
        "id": "1Cpuck-pO-wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "final_model.summary()"
      ],
      "metadata": {
        "id": "RP0e6zYjPpys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "final_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rat\n",
        " e=0.0001),\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "82eXHb_5Pm6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert image lists to numpy arrays\n",
        "X_train = np.array(X_train)\n",
        "X_val = np.array(X_val)\n",
        "X_test = np.array(X_test)"
      ],
      "metadata": {
        "id": "_MNQ8-CGPkG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rescale and normalize images\n",
        "X_train = X_train / 255.0\n",
        "X_val = X_val / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "metadata": {
        "id": "fF9Yv3PrPcf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model for 50 epochs\n",
        "history = final_model.fit([X_train, X_train_hog], y_train,\n",
        "                           validation_data=([X_val, X_val_hog],y_val),\n",
        "                           epochs=50)"
      ],
      "metadata": {
        "id": "vFrgEFDaO-4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the training history (accuracy and loss)\n",
        "plt.figure(figsize=(12, 4))"
      ],
      "metadata": {
        "id": "aoqXSv7dPxlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation\n",
        "Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "guYxBll_PxiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U7hBEvT-P7W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = final_model.evaluate([X_test,\n",
        "X_test_hog], y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "4tVi1Uj8QD_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "test_preds = final_model.predict([X_test, X_test_hog])\n",
        "test_labels = []\n",
        "\n",
        "for label in y_test:\n",
        "    test_labels.append(label)  # Append the label directly"
      ],
      "metadata": {
        "id": "LgpEZ1eYQD8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "conf_mat = confusion_matrix(test_labels, np.argmax(test_preds,\n",
        "axis=1))\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_mat, annot=True, fmt='g', cmap='Blues',\n",
        "xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tX9bAcgqQDvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(test_labels, np.argmax(test_preds,\n",
        "axis=1), target_names=class_names))"
      ],
      "metadata": {
        "id": "tZn06C-OQDsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC Curve\n",
        "fpr, tpr, _ = roc_curve(test_labels, test_preds[:, 1])\n",
        "roc_auc = auc(fpr, tpr)"
      ],
      "metadata": {
        "id": "qFFWh8fbQSCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ROC Curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area\n",
        "= {:.2f})'.format(roc_auc))\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mQ6tC0FEQR1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model as .h5 file\n",
        "final_model.save('parkinson_model.h5')"
      ],
      "metadata": {
        "id": "JxTu_tXMQRyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model from .h5 file\n",
        "loaded_model = models.load_model('parkinson_model.h5')"
      ],
      "metadata": {
        "id": "c8VNho49QfAz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}